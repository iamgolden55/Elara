#!/usr/bin/env python3
"""
ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–
                            ELARA AI - MAIN APPLICATION
                        The Heart of Your Medical AI Assistant!
ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–ğŸ¥ğŸ¤–
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import sys
from pathlib import Path

# Add project root to Python path for imports
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# Import our custom modules (we'll create these!)
from routes import chat_router
from models import ModelManager
from config import Settings

# Create FastAPI app instance - THE BRAIN! ğŸ§ 
app = FastAPI(
    title="Elara AI Medical Assistant",
    description="A multilingual AI assistant for medical questions and support",
    version="1.0.0",
    docs_url="/docs",  # Swagger UI at /docs
    redoc_url="/redoc"  # ReDoc at /redoc
)

# Load configuration
settings = Settings()

# Add CORS middleware - allows frontend to talk to backend ğŸŒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],  # React frontend
    allow_credentials=True,
    allow_methods=["*"],  # Allow all HTTP methods
    allow_headers=["*"],  # Allow all headers
)

# Global model manager - our AI chef! ğŸ‘¨â€ğŸ³
model_manager = None

@app.on_event("startup")
async def startup_event():
    """Initialize the AI models when server starts"""
    global model_manager
    
    print("ğŸš€ ELARA AI STARTING UP...")
    print("=" * 50)
    
    try:
        # Initialize model manager
        model_manager = ModelManager(settings)
        
        # Load models (start with lightweight ones)
        await model_manager.initialize_models()
        
        print("âœ… Elara AI is ready to help!")
        print("ğŸ¥ Medical AI Assistant: ONLINE")
        print("ğŸŒ Multilingual Support: READY")
        print("ğŸ¤– Models: LOADED")
        
    except Exception as e:
        print(f"âŒ Startup Error: {e}")
        print("ğŸ’¡ Starting without AI models (API-only mode)")

@app.on_event("shutdown")
async def shutdown_event():
    """Clean up when server shuts down"""
    global model_manager
    
    print("ğŸ›‘ ELARA AI SHUTTING DOWN...")
    
    if model_manager:
        await model_manager.cleanup()
    
    print("âœ… Cleanup complete. Goodbye! ğŸ‘‹")

# Health check endpoint - is the server alive? â¤ï¸
@app.get("/health")
async def health_check():
    """Check if the API is running and models are loaded"""
    global model_manager
    
    status = {
        "status": "healthy",
        "service": "Elara AI Medical Assistant",
        "version": "1.0.0",
        "models_loaded": False
    }
    
    if model_manager:
        status["models_loaded"] = model_manager.are_models_loaded()
        status["available_models"] = model_manager.get_available_models()
    
    return status

# Root endpoint - welcome message! ğŸ‘‹
@app.get("/")
async def root():
    """Welcome message for Elara AI"""
    return {
        "message": "Welcome to Elara AI Medical Assistant! ğŸ¥ğŸ¤–",
        "description": "Your multilingual AI companion for medical questions",
        "endpoints": {
            "health": "/health",
            "chat": "/chat",
            "docs": "/docs",
            "redoc": "/redoc"
        },
        "features": [
            "ğŸ§  Medical Q&A with AI",
            "ğŸŒ 200+ languages supported",
            "ğŸ™ï¸ Voice input/output",
            "ğŸ“Š Evidence-based responses",
            "ğŸ”’ Privacy-first design"
        ]
    }

# Include chat routes - the main functionality! ğŸ’¬
app.include_router(chat_router, prefix="/chat", tags=["chat"])

# Global exception handler - catch all errors! ğŸ›¡ï¸
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """Handle unexpected errors gracefully"""
    print(f"âŒ Unexpected error: {exc}")
    
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": "Something went wrong. Please try again.",
            "support": "Contact support if this persists."
        }
    )

# Add middleware to inject model manager into requests
@app.middleware("http")
async def add_model_manager(request, call_next):
    """Add model manager to request state"""
    request.state.model_manager = model_manager
    response = await call_next(request)
    return response

# Development server runner ğŸƒâ€â™‚ï¸
if __name__ == "__main__":
    print("\nğŸ¯ STARTING ELARA AI DEVELOPMENT SERVER")
    print("=" * 50)
    print("ğŸ¥ Medical AI Assistant - FastAPI Backend")
    print("ğŸŒ Access at: http://localhost:8000")
    print("ğŸ“š API Docs: http://localhost:8000/docs")
    print("ğŸ’¡ Stop with: Ctrl+C")
    print("=" * 50)
    
    # Run the server with auto-reload for development
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # Auto-restart on code changes
        log_level="info"
    )
